# Renderer Context

## A. Strategy: Dual-Path Architecture
The renderer supports two distinct strategies for capturing frames:

1.  **CanvasStrategy** (Default):
    -   Best for: High-performance canvas-based animations (WebGL, Three.js, PixiJS).
    -   Mechanism: Uses `WebCodecs` (VideoEncoder) to capture frames directly from the canvas context.
    -   Optimizations:
        -   Supports VP8/VP9/AV1 via IVF container.
        -   Supports H.264 (avc1) via raw Annex B stream (no container).
        -   Falls back to `canvas.toDataURL()` if WebCodecs is unavailable.
    -   Transparency: Supported (if `pixelFormat` is `yuva420p` or similar).

2.  **DomStrategy**:
    -   Best for: CSS/DOM-based animations.
    -   Mechanism: Uses `page.screenshot()` (via Playwright) to capture the viewport.
    -   Features: Includes asset preloading (images, fonts, media) to prevent artifacts.

Both strategies pipe captured frames to a persistent FFmpeg process via stdin.

## B. File Tree
```
packages/renderer/
├── src/
│   ├── strategies/
│   │   ├── RenderStrategy.ts      # Interface
│   │   ├── CanvasStrategy.ts      # WebCodecs/Canvas implementation
│   │   ├── DomStrategy.ts         # Screenshot implementation
│   ├── drivers/
│   │   ├── TimeDriver.ts          # Interface for time control
│   │   ├── CdpTimeDriver.ts       # CDP-based deterministic timing
│   │   └── SeekTimeDriver.ts      # RAF/Polyfill-based timing
│   ├── utils/
│   │   └── FFmpegBuilder.ts       # FFmpeg argument generation logic
│   ├── index.ts                   # Main entry point (Renderer class)
│   ├── types.ts                   # Shared interfaces
│   └── concat.ts                  # Video concatenation utility
└── tests/                         # Verification scripts
```

## C. Configuration
The `Renderer` is configured via `RendererOptions`:

```typescript
interface RendererOptions {
  width: number;
  height: number;
  fps: number;
  durationInSeconds: number;
  mode?: 'canvas' | 'dom';
  intermediateVideoCodec?: string; // e.g., 'vp8', 'avc1.42001f'
  videoBitrate?: string;           // e.g., '5M'
  pixelFormat?: string;            // e.g., 'yuv420p', 'yuva420p'
  audioFilePath?: string;          // Single track
  audioTracks?: (string | AudioTrackConfig)[]; // Multi-track mixing
  inputProps?: Record<string, any>; // Dynamic props injection
  ffmpegPath?: string;
  startFrame?: number;             // For distributed rendering
  // ... (crf, preset, videoCodec)
}
```

## D. FFmpeg Interface
The renderer spawns FFmpeg with arguments generated by `FFmpegBuilder`.
- **Inputs**:
    -   Video: Pipes from stdin (`-f ivf` for VPx, `-f h264` for AVC, or `-f image2pipe` for screenshots).
    -   Audio: `-i <path>` for each track.
- **Filters**:
    -   `adelay`: For audio offsets.
    -   `volume`: For track volume.
    -   `amix`: For mixing multiple tracks.
- **Output**:
    -   Encodes to H.264 (MP4) by default, configurable via `videoCodec`.
    -   Writes to the specified `outputPath`.
