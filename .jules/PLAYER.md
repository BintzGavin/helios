<!-- AGENT_SKIP_START: This section is for human readers only. Planning agents should skip to the next section. -->
<details>
<summary>DISCLAIMER: This repository is an active experiment in autonomous software engineering.</summary>


> **Current Status:** ðŸš§ **Alpha / Self-Driving**

This codebase is primarily managed and developed by a fleet of AI agents running on **Google's Jules** platform. It is **not** currently intended for production use.

### How It Works
The system uses a **Black Hole Architecture**â€”a planning-execution cycle designed to simulate a fully autonomous engineering team where agents continuously pull the codebase toward the documented vision:

1.  **Autonomous Scheduling:** "Prompts" are executed daily to drive the development lifecycle.
    * **Morning Phase:** Planning agents scan the codebase and `README` vision, identifying missing features or bugs to populate their own backlog.
    * **Afternoon Phase:** Execution agents implement the planned tasks.
    * **End-of-Day Phase:** Scribe agent consolidates progress logs and regenerates the context knowledge base for the next day's planning cycle.
2.  **Feedback Loops:** Agents are empowered to run their own validation using:
    * **Playwright** for End-to-End (E2E) testing.
    * **Visual Regression** via screenshot analysis.
    * **Unit Tests** (Vitest) for logic verification.
    * **Ad-hoc Bash Commands** for environment diagnostics.
3.  **Human-in-the-Loop:** While I act as the "Lead Architect" providing the high-level vision, my involvement is primarily limited to glancing at and merging Pull Requests generated by **Jules** and reviewed by a separate **GitHub Copilot** agent.

### Agent Prompts

For transparency and educational purposes, the complete prompts used to orchestrate the agent swarm are available in the [`docs/prompts/`](./docs/prompts/) directory.

**Expect rapid changes, experimental commits, and occasional "hallucinated" refactors as the swarm learns to optimize its own workflow.**
</details>
<!-- AGENT_SKIP_END -->

## v0.31.0 - Standard Media API Completeness
**Learning:** Marking "Standard Media API" as complete without `readyState`, `networkState` and loading events leaves the component incompatible with many video wrappers. Parity requires the full lifecycle, not just playback methods.
**Action:** When scoping "Standard API" tasks, explicitly list required states and events from the spec to ensure full coverage.

## v0.32.0 - Deep API Parity
**Learning:** Even with lifecycle events, `HTMLMediaElement` compatibility requires getters like `seeking`, `buffered`, and `videoWidth`. Libraries check these properties before attempting playback or UI updates.
**Action:** When implementing "Standard API", audit the `HTMLMediaElement` interface for *all* read-only properties, not just methods and events.

## v0.33.1 - HTMLMediaElement Parity Gaps
**Learning:** "Deep API Parity" was marked complete, but critical properties like `error` and `currentSrc` were missed. Wrappers rely on `error` property to diagnose failures after an event.
**Action:** Audit `HTMLMediaElement` spec line-by-line when claiming parity, especially for error handling and source resolution properties.

## v0.38.0 - Native Engine Capabilities
**Learning:** The player was implementing client-side looping logic which was redundant because the core engine supports `setLoop` natively.
**Action:** Always check the core engine capabilities (via memory or docs) before implementing logic in the player view layer to avoid redundancy and synchronization issues.

## [v0.39.0] - Export Respects Loop Region
**Learning:** Client-Side Export was ignoring `playbackRange`, exporting the full timeline instead of the user's selected loop region. This discrepancy between "what I see" (preview looping) and "what I get" (export full) breaks user expectations.
**Action:** When implementing export features, always verify that they respect the active view state (loop region, muted state, etc.) to ensure WYSIWYG.
